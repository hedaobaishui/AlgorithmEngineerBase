# 1 base infor
初赛A榜：5月10日10:00-6月1日12:00。每队每天有4次提交结果的机会，系统进行实时评测并返回成绩（5月10日10:00-5月13日10:00期间，排行榜不公布）。5月13日10:00开始，排行榜开始公布，且每小时进行更新，按照评测指标从高到低排序。排行榜将选择参赛队伍在本阶段的历史最优成绩进行排名展示。

初赛结束，以B榜成绩作为初赛成绩依照，要求TOP150团队提交代码审核，规范详见**“代码规范”**文档，代码提交截止时间6月3日12:00。组委会将审核并取消作弊等不合理行为的团队比赛资格，晋级空缺名额后补。初赛成绩符合要求且通过实名认证的排名前100名的参赛队伍将进入复赛。

[比赛网址](https://tianchi.aliyun.com/competition/entrance/531962/information)
本次比赛采用的数据集为2019-2021年4-9月江苏省气象雷达及自动站观测要素数据，数据集由江苏省气象台制作，以灰度图形式存储（格式为PNG）。

本次算法比赛是一项时间序列预测大赛，选手需要基于过去已发生的气象时间序列数据，也就是过去发生的气象雷达影像和自动站观测到的气象要素结构化数据，预测未来两小时的气象雷达影像和自动站观测到的气象要素结构化数据。选手的算法模型将会用于上线实际运行，在实际发生的气象过程中验证其准确度。

1 ）数据集描述

【气象雷达数据集】

气象雷达数据集是雷达回波数据的时间序列，其物理含义为3公里等高面的基本反射率因子。大气中的水滴含量越高，则雷达基本反射率越高。本数据集是对江苏多部S波段气象雷达质量控制及组网拼图后得到的，覆盖整个江苏省区域面积。数据取值范围为0-70（单位：dBZ），水平分辨率为0.01°（约1公里），时间分辨率为6分钟，单时次数据（即单张图片）的网格尺寸为480×560像素。

【自动站观测要素数据集】

自动站观测要素数据集包含降水和平均风要素，通过将江苏及其周边地区气象自动观测站数据插值到均匀网格后得到。其中降水要素为自动站6分钟累积降水量，即截至当前时刻6分钟内降水观测量的累加值，取值范围为0-10（单位：mm）。平均风要素由自动站观测得到，取值范围为0-35（单位m/s）。数据集的水平分辨率为0.01°（约1公里），时间分辨率为6分钟，单时次数据（即单张图片）的网格数为480×560像素。

2 ）数据集说明

初赛提供的数据包含时间、空间匹配的雷达回波（Radar）、降水（Precip）和平均风（Wind）三类数据，由Train、TestA以及TestB组成，使用说明如下：

在训练集Train提供的所有数据中包含2万+次有强天气发生的过程，并以案例的形式呈现在对应的Train.csv中供选手参照，其中每行的40列为一次案例，各行之间相互独立，每个案例以序号.png的形式列出。以截取自Train.csv的图1为例，第一行有40列，对应为00时06分—04时逐6分钟的40张图片序号，前20张图片为过去2小时的数据（00时06分—02时），后20张图片为后2小时数据（02时06分—04时），该序号同时适用于Radar、Precip和Wind，可据此从原始数据文件中索引找到相应图片并进行模型构建，对未来2小时（20张图片）的Radar、Precip和Wind进行预测（可建立1个或多个模型），当然，选手也可以自行确定训练数据的使用方法；

文件TestA中包含的数据存放形式与Train完全一致，并配有对应的TestA.csv，当中列出了2000+次强天气过程，参赛选手既可将其作为验证集用于对模型调试，也可以将其与Train混在一起并自行切分训练集和验证集；

气象雷达数据集是雷达回波数据的时间序列，其物理含义为3公里等高面的基本反射率因子。大气中的水滴含量越高，则雷达基本反射率越高。本数据集是对江苏多部S波段气象雷达质量控制及组网拼图后得到的，覆盖整个江苏省区域面积。数据取值范围为0-70（单位：dBZ），水平分辨率为0.01°（约1公里），时间分辨率为6分钟，单时次数据（即单张图片）的网格尺寸为480×560像素。

【自动站观测要素数据集】

自动站观测要素数据集包含降水和平均风要素，通过将江苏及其周边地区气象自动观测站数据插值到均匀网格后得到。其中降水要素为自动站6分钟累积降水量，即截至当前时刻6分钟内降水观测量的累加值，取值范围为0-10（单位：mm）。平均风要素由自动站观测得到，取值范围为0-35（单位m/s）。数据集的水平分辨率为0.01°（约1公里），时间分辨率为6分钟，单时次数据（即单张图片）的网格数为480×560像素。
![评价机制](https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/165182944342133461651829443529.jpeg)
![2](https://tianchi-public.oss-cn-hangzhou.aliyuncs.com/public/files/forum/165181877784047881651818777347.jpeg)
**空间、时间匹配**
# 2．模型
* axial attention:轴注意力机制　既融合全局信息，保持长距离的空间依赖性，又降低计算量呢
* convGRU
GRU神经网络是一种循环神经网络，是LSTM的变种，在LSTM神经网络的基础上优化了cell结构减少了参数，加快了训练速度；
* 几个输出　就训练几个sampler
* sampler的8*8*8输入是256的32倍下采样
* 对更高的降雨加权、输出值clipped最大值
* 估计时:输入是1536*1280 latent conditioning stack 是下采样32倍的结果(48*40*8)
* 480*560->（15*18*8）/除不尽１８＊３２＝５７６多１６
# 3.数据

* test
雷达数据 31700~31814 有噪声
# 4.TODO

* 时间序列图片
* 预测输出为图片
* 40 张图片(４个小时)　预测后２个小时的天气情况(20张图片) 训练样本可以有[1-20,2-21,3-22,4-23,....20-40]预测[一张或者多张]
* 将生成器换成Styleswin
* 考虑多个维度$\color{red}{降雨}$　$\color{red}{风速}$　$\color{red}{云图}$　的相互影响关系由于在空间和时间上是相互匹配的
* 同时输入**雷达图、风速、降雨**输出**雷达图、风速、降雨**如果分别训练的话需要三个模型　每个模型训练７天　一共２１天呢　没时间
* **输入**三个数据间如何编码加权　多层MLP　还需要resize
* **输出**480x560*3　３个通道分别为雷达图、风速、降雨
* 数据平衡　有些数据可能没用
* 通过４个输入预测18个输出
* 是否需要　增加 **海拔数据**作为特征
* 海拔位置和时间嵌入方式(paper 38)
* 现在小数据上训练　看是否能够过拟合
* 将Gan网络替换为styleswin**缺省　使用是否会导致参数量爆炸　是否好训练**
* 考虑风速影响　及移动范围 max= 35*60*60/1000/h=126km/h 预测未来2h　则输出为252*252+crop_size
* 数据清洗　统计雷达[0~70]、风速[0,35]、降雨[0.0~10]数值分布
* GAN 和　视频超分
* 根据判分规则　预测极值越大得分权重越高
* 